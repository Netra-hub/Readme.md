{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Netra-hub/Readme.md/blob/main/Bonus_calculator_system_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um0Qx-_cbgaL"
      },
      "source": [
        "## ***RM Bonus calculator using LangGraph***\n",
        "\n",
        "## Overview\n",
        "This notebook presents an automated RM Bonus calculator implemented using LangGraph and an LLM model.\n",
        "\n",
        "## Key Components\n",
        "1. State Graph: Defines the workflow of the grading process\n",
        "2. LLM Model: Provides the underlying language understanding and analysis\n",
        "3. Bonus Functions: Separate functions for each evaluation criterion\n",
        "4. Conditional Logic: Determines the flow of the calculating process based on interim scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjpYcj08bgaQ"
      },
      "source": [
        "## Setup and Imports\n",
        "\n",
        "This cell imports necessary libraries and sets up the OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from langchain_openai import ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import Field, SecretStr\n",
        "from langchain_core.utils.utils import secret_from_env\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import os\n",
        "import re\n",
        "\n",
        "class ChatOpenRouter(ChatOpenAI):\n",
        "    openai_api_key: Optional[SecretStr] = Field(\n",
        "        alias=\"api_key\",\n",
        "        default_factory=secret_from_env(\"OPENROUTER_API_KEY\", default=None),\n",
        "    )\n",
        "\n",
        "    @property\n",
        "    def lc_secrets(self) -> dict[str, str]:\n",
        "        return {\"openai_api_key\": \"OPENROUTER_API_KEY\"}\n",
        "\n",
        "    def __init__(self, openai_api_key: Optional[str] = None, **kwargs):\n",
        "        openai_api_key = openai_api_key or os.environ.get(\"OPENROUTER_API_KEY\")\n",
        "        super().__init__(\n",
        "            base_url=\"https://openrouter.ai/api/v1\",\n",
        "            openai_api_key=openai_api_key,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "# Example usage\n",
        "openrouter_model = ChatOpenRouter(model_name=\"anthropic/claude-3.7-sonnet:thinking\")"
      ],
      "metadata": {
        "id": "F4GMyuuVgO54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1rk3ebuTbgaR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "21b95ab4-b0b7-4c03-9676-a7820f5dbbcc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d888b7e1ee13>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "load_dotenv()\n",
        "os.environ[\"__n8n_BLANK_VALUE_e5362baf-c777-4d57-a609-6eaf1f9e87f6\"] = os.getenv('__n8n_BLANK_VALUE_e5362baf-c777-4d57-a609-6eaf1f9e87f6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oi4jURtbgaS"
      },
      "source": [
        "## State Definition\n",
        "\n",
        "This cell defines the State class, which represents the state of our grading process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzFPDF0tbgaT"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    \"\"\"Represents the state of the essay grading process.\"\"\"\n",
        "    essay: str\n",
        "    relevance_score: float\n",
        "    grammar_score: float\n",
        "    structure_score: float\n",
        "    depth_score: float\n",
        "    final_score: float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvYt-RTqbgaT"
      },
      "source": [
        "## Language Model Initialization\n",
        "\n",
        "This cell initializes the ChatOpenAI model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjN2C0oDbgaU"
      },
      "outputs": [],
      "source": [
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BsdCVN_bgaV"
      },
      "source": [
        "## Grading Functions\n",
        "\n",
        "This cell defines the functions used in the grading process, including score extraction and individual grading components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z2ABJBybgaV"
      },
      "outputs": [],
      "source": [
        "def extract_score(content: str) -> float:\n",
        "    \"\"\"Extract the numeric score from the LLM's response.\"\"\"\n",
        "    match = re.search(r'Score:\\s*(\\d+(\\.\\d+)?)', content)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    raise ValueError(f\"Could not extract score from: {content}\")\n",
        "\n",
        "def check_relevance(state: State) -> State:\n",
        "    \"\"\"Check the relevance of the essay.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Analyze the relevance of the following essay to the given topic. \"\n",
        "        \"Provide a relevance score between 0 and 1. \"\n",
        "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
        "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
        "    try:\n",
        "        state[\"relevance_score\"] = extract_score(result.content)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in check_relevance: {e}\")\n",
        "        state[\"relevance_score\"] = 0.0\n",
        "    return state\n",
        "\n",
        "def check_grammar(state: State) -> State:\n",
        "    \"\"\"Check the grammar of the essay.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Analyze the grammar and language usage in the following essay. \"\n",
        "        \"Provide a grammar score between 0 and 1. \"\n",
        "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
        "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
        "    try:\n",
        "        state[\"grammar_score\"] = extract_score(result.content)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in check_grammar: {e}\")\n",
        "        state[\"grammar_score\"] = 0.0\n",
        "    return state\n",
        "\n",
        "def analyze_structure(state: State) -> State:\n",
        "    \"\"\"Analyze the structure of the essay.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Analyze the structure of the following essay. \"\n",
        "        \"Provide a structure score between 0 and 1. \"\n",
        "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
        "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
        "    try:\n",
        "        state[\"structure_score\"] = extract_score(result.content)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in analyze_structure: {e}\")\n",
        "        state[\"structure_score\"] = 0.0\n",
        "    return state\n",
        "\n",
        "def evaluate_depth(state: State) -> State:\n",
        "    \"\"\"Evaluate the depth of analysis in the essay.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Evaluate the depth of analysis in the following essay. \"\n",
        "        \"Provide a depth score between 0 and 1. \"\n",
        "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
        "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
        "    )\n",
        "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
        "    try:\n",
        "        state[\"depth_score\"] = extract_score(result.content)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in evaluate_depth: {e}\")\n",
        "        state[\"depth_score\"] = 0.0\n",
        "    return state\n",
        "\n",
        "def calculate_final_score(state: State) -> State:\n",
        "    \"\"\"Calculate the final score based on individual component scores.\"\"\"\n",
        "    state[\"final_score\"] = (\n",
        "        state[\"relevance_score\"] * 0.3 +\n",
        "        state[\"grammar_score\"] * 0.2 +\n",
        "        state[\"structure_score\"] * 0.2 +\n",
        "        state[\"depth_score\"] * 0.3\n",
        "    )\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE5Iqr6SbgaW"
      },
      "source": [
        "## Workflow Definition\n",
        "\n",
        "This cell defines the grading workflow using StateGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHuD0Uy_bgaW"
      },
      "outputs": [],
      "source": [
        "# Initialize the StateGraph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"check_relevance\", check_relevance)\n",
        "workflow.add_node(\"check_grammar\", check_grammar)\n",
        "workflow.add_node(\"analyze_structure\", analyze_structure)\n",
        "workflow.add_node(\"evaluate_depth\", evaluate_depth)\n",
        "workflow.add_node(\"calculate_final_score\", calculate_final_score)\n",
        "\n",
        "# Define and add conditional edges\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_relevance\",\n",
        "    lambda x: \"check_grammar\" if x[\"relevance_score\"] > 0.5 else \"calculate_final_score\"\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_grammar\",\n",
        "    lambda x: \"analyze_structure\" if x[\"grammar_score\"] > 0.6 else \"calculate_final_score\"\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"analyze_structure\",\n",
        "    lambda x: \"evaluate_depth\" if x[\"structure_score\"] > 0.7 else \"calculate_final_score\"\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"evaluate_depth\",\n",
        "    lambda x: \"calculate_final_score\"\n",
        ")\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"check_relevance\")\n",
        "\n",
        "# Set the exit point\n",
        "workflow.add_edge(\"calculate_final_score\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgrvqTh2bgaW"
      },
      "source": [
        "## Essay Grading Function\n",
        "\n",
        "This cell defines the main function to grade an essay using the defined workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFT4HaTMbgaW"
      },
      "outputs": [],
      "source": [
        "def grade_essay(essay: str) -> dict:\n",
        "    \"\"\"Grade the given essay using the defined workflow.\"\"\"\n",
        "    initial_state = State(\n",
        "        essay=essay,\n",
        "        relevance_score=0.0,\n",
        "        grammar_score=0.0,\n",
        "        structure_score=0.0,\n",
        "        depth_score=0.0,\n",
        "        final_score=0.0\n",
        "    )\n",
        "    result = app.invoke(initial_state)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_llg4hgbgaX"
      },
      "source": [
        "## Sample Essay\n",
        "\n",
        "This cell contains a sample essay for testing the grading system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcwUKb7QbgaX"
      },
      "outputs": [],
      "source": [
        "sample_essay = \"\"\"\n",
        "    The Impact of Artificial Intelligence on Modern Society\n",
        "\n",
        "    Artificial Intelligence (AI) has become an integral part of our daily lives,\n",
        "    revolutionizing various sectors including healthcare, finance, and transportation.\n",
        "    This essay explores the profound effects of AI on modern society, discussing both\n",
        "    its benefits and potential challenges.\n",
        "\n",
        "    One of the most significant impacts of AI is in the healthcare industry.\n",
        "    AI-powered diagnostic tools can analyze medical images with high accuracy,\n",
        "    often surpassing human capabilities. This leads to earlier detection of diseases\n",
        "    and more effective treatment plans. Moreover, AI algorithms can process vast\n",
        "    amounts of medical data to identify patterns and insights that might escape\n",
        "    human observation, potentially leading to breakthroughs in drug discovery and\n",
        "    personalized medicine.\n",
        "\n",
        "    In the financial sector, AI has transformed the way transactions are processed\n",
        "    and monitored. Machine learning algorithms can detect fraudulent activities in\n",
        "    real-time, enhancing security for consumers and institutions alike. Robo-advisors\n",
        "    use AI to provide personalized investment advice, democratizing access to\n",
        "    financial planning services.\n",
        "\n",
        "    The transportation industry is another area where AI is making significant strides.\n",
        "    Self-driving cars, powered by complex AI systems, promise to reduce accidents\n",
        "    caused by human error and provide mobility solutions for those unable to drive.\n",
        "    In logistics, AI optimizes routing and inventory management, leading to more\n",
        "    efficient supply chains and reduced environmental impact.\n",
        "\n",
        "    However, the rapid advancement of AI also presents challenges. There are concerns\n",
        "    about job displacement as AI systems become capable of performing tasks\n",
        "    traditionally done by humans. This raises questions about the need for retraining\n",
        "    and reskilling the workforce to adapt to an AI-driven economy.\n",
        "\n",
        "    Privacy and ethical concerns also arise with the increasing use of AI. The vast\n",
        "    amount of data required to train AI systems raises questions about data privacy\n",
        "    and consent. Additionally, there are ongoing debates about the potential biases\n",
        "    in AI algorithms and the need for transparent and accountable AI systems.\n",
        "\n",
        "    In conclusion, while AI offers tremendous benefits and has the potential to solve\n",
        "    some of humanity's most pressing challenges, it also requires careful consideration\n",
        "    of its societal implications. As we continue to integrate AI into various aspects\n",
        "    of our lives, it is crucial to strike a balance between technological advancement\n",
        "    and ethical considerations, ensuring that the benefits of AI are distributed\n",
        "    equitably across society.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZNkIwKHbgaX"
      },
      "source": [
        "## Grading the Sample Essay\n",
        "\n",
        "This cell demonstrates how to use the grading system on the sample essay and display the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0wMD2-cbgaX",
        "outputId": "9c7f2211-3584-4801-dc01-c823e53e3371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Essay Score: 0.86\n",
            "\n",
            "Relevance Score: 1.00\n",
            "Grammar Score: 0.90\n",
            "Structure Score: 0.85\n",
            "Depth Score: 0.70\n"
          ]
        }
      ],
      "source": [
        "# Grade the sample essay\n",
        "result = grade_essay(sample_essay)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Final Essay Score: {result['final_score']:.2f}\\n\")\n",
        "print(f\"Relevance Score: {result['relevance_score']:.2f}\")\n",
        "print(f\"Grammar Score: {result['grammar_score']:.2f}\")\n",
        "print(f\"Structure Score: {result['structure_score']:.2f}\")\n",
        "print(f\"Depth Score: {result['depth_score']:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}